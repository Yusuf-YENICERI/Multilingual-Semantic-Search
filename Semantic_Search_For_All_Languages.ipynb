{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yusuf-YENICERI/Semantic-Search-For-All-Languages/blob/master/Semantic_Search_For_All_Languages.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Package Installation"
      ],
      "metadata": {
        "id": "hy1McifvhPXA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzUter80td8o"
      },
      "source": [
        "\n",
        "!pip install sentence-transformers\n",
        "!pip install faiss-cpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aecWwyrutyef"
      },
      "source": [
        "# Encode docs using sentence-transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentence Transformers provides open source models to enable encoding of text data. So you can either use this model or you can use embedding models of openai in the coming sections. Do not forget, the models in sentence transformers are free but not openai."
      ],
      "metadata": {
        "id": "lMlsTM-whpbt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLpFgyStthUM"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "encoder = SentenceTransformer('multi-qa-mpnet-base-dot-v1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Y4cyM65tiUq"
      },
      "source": [
        "data = [\n",
        "    'Hayat nasıl gidiyor diyenlere aslında süper gidiyor Elhamdülillah',\n",
        "    'Silahlar savaş için oldukça gereklidir. Çünkü hayat memat meselesi',\n",
        "]\n",
        "encoded_data = encoder.encode(allText)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code snippet above includes two sentence in Turkish as an example. You can add or modify there to have different cases."
      ],
      "metadata": {
        "id": "cgjuxurdiNBb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find in PDF"
      ],
      "metadata": {
        "id": "q5cuOxUt_1tx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to encode PDF you can run this snippet. If you don't want, skip this part."
      ],
      "metadata": {
        "id": "XkOczRxphfjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "print(\"Choose a single file\")\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "obGxMlbvDugu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "id": "IxvubX9e_8PE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "\n",
        "# set path to your pdf\n",
        "reader = PdfReader('/content/example.pdf')\n",
        "\n",
        "# printing number of pages in pdf file\n",
        "print(len(reader.pages))\n",
        "allText =[]\n",
        "for page in reader.pages:\n",
        "# split page sentences with '.' character to split them one by one\n",
        "    for text in page.extract_text().split('.'):\n",
        "        if len(text)>0:\n",
        "            allText.append(text)\n",
        "print(allText)"
      ],
      "metadata": {
        "id": "KG3rgYMNACfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encode using openai"
      ],
      "metadata": {
        "id": "rsLGHyy_LudR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to use openai embedding models to encode your data you can use this section."
      ],
      "metadata": {
        "id": "o2Y37n2rjvPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%capture\n",
        "!pip install openai"
      ],
      "metadata": {
        "id": "G4ZDZKJ2Lzub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "openai.api_key = \"your-openai-api-key\"\n",
        "\n",
        "openai.Engine.list()  # check we have authenticated"
      ],
      "metadata": {
        "id": "YC05e-nIL1uT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def encode_open(input):\n",
        "# you can change model if you want different\n",
        "    MODEL = \"text-embedding-ada-002\"\n",
        "    res = openai.Embedding.create(\n",
        "       input=input, engine=MODEL\n",
        "    )\n",
        "    embeds = [record['embedding'] for record in res['data']]\n",
        "    import torch\n",
        "    embeds=torch.FloatTensor(embeds)\n",
        "    return embeds"
      ],
      "metadata": {
        "id": "VHZ6adRIMVxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input=['Hayat nasıl gidiyor diyenlere aslında süper gidiyor Elhamdülillah','Silahlar savaş için oldukça gereklidir. Çünkü hayat memat meselesi']\n",
        "encoded_data=encode_open(input)"
      ],
      "metadata": {
        "id": "0gVaNadBkuUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to use PDF for encoding you can run the two code snippets below."
      ],
      "metadata": {
        "id": "1-vn-BYlkfLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "allText"
      ],
      "metadata": {
        "id": "VwrytY-EkZwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input=['Hayat nasıl gidiyor diyenlere aslında süper gidiyor Elhamdülillah','Silahlar savaş için oldukça gereklidir. Çünkü hayat memat meselesi']\n",
        "encoded_data=encode_open(allText)"
      ],
      "metadata": {
        "id": "gNb7JqCvmMYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_WMwbYctjQO"
      },
      "source": [
        "# Add to index"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will add the encoded texts into the FAISS(semantic search similarity library) inshaAllah. So the text data will be add into the database."
      ],
      "metadata": {
        "id": "JDMhVGrfk340"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "d=encoded_data.shape[1]\n",
        "d"
      ],
      "metadata": {
        "id": "TNxrjiCawPjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4FiOXnEtl1f"
      },
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# IndexFlatIP: Flat inner product (for small datasets)\n",
        "# IndexIDMap: store document ids in the index as well\n",
        "index = faiss.IndexIDMap(faiss.IndexFlatIP(d))\n",
        "index.add_with_ids(encoded_data, np.arange(encoded_data.shape[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Xjl64n1tnGn"
      },
      "source": [
        "# Search for question"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can search your text using the functions below, if you use openai, run search_openai function."
      ],
      "metadata": {
        "id": "_KKP5zlQmAE6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYBDxMtxtoxk"
      },
      "source": [
        "def search(query, k=7):\n",
        "    query_vector = encoder.encode([query])\n",
        "    top_k = index.search(query_vector, k)\n",
        "    print(top_k)\n",
        "    return [\n",
        "        input[_id] for _id in top_k[1][0]\n",
        "    ]\n",
        "\n",
        "search(\"hayat iyi gidiyor mu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_pdf(query, k=7):\n",
        "    query_vector = encoder.encode([query])\n",
        "    top_k = index.search(query_vector, k)\n",
        "    print(top_k)\n",
        "    return [\n",
        "        allText[_id] for _id in top_k[1][0]\n",
        "    ]\n",
        "\n",
        "search_pdf(\"hayat iyi gidiyor mu\")"
      ],
      "metadata": {
        "id": "jfamahaqmwAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_openai(query, k=5):\n",
        "    query_vector = encode_open([query])\n",
        "    top_k = index.search(query_vector, k)\n",
        "    print(top_k)\n",
        "    return [\n",
        "        input[_id] for _id in top_k[1][0]\n",
        "    ]\n",
        "\n",
        "search_openai(\"hayat iyi gidiyor mu\")"
      ],
      "metadata": {
        "id": "e--xbQ_e2Yuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_openai_pdf(query, k=5):\n",
        "    query_vector = encode_open([query])\n",
        "    top_k = index.search(query_vector, k)\n",
        "    print(top_k)\n",
        "    return [\n",
        "        allText[_id] for _id in top_k[1][0]\n",
        "    ]\n",
        "\n",
        "search_openai_pdf(\"hayat iyi gidiyor mu\")"
      ],
      "metadata": {
        "id": "iPVcbuWkm7KU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwaYAjnYtp24"
      },
      "source": [
        "# Save encoded texts"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "İf you want to save the encoded texts, you can use the cell below."
      ],
      "metadata": {
        "id": "tW-l_Z1lymYU"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-oY5Ppptr6A"
      },
      "source": [
        "path = './faiss.index'\n",
        "\n",
        "# Save index\n",
        "faiss.write_index(index, path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD7mU1C7tuMq"
      },
      "source": [
        "# Load encoded texts"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can load back the encoded texts providing the path of index."
      ],
      "metadata": {
        "id": "qf2Mh_u9zWxC"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVo8cGzTttE3"
      },
      "source": [
        "index = faiss.read_index(path)\n",
        "search(\"hayat iyi gidiyor mu\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}